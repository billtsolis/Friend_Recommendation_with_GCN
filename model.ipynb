{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70716bc1-9511-41da-90af-d9c273b5d0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as gnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.nn import GCNConv \n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import roc_auc_score, ndcg_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61707cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(TwitterDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['twitter_combined.txt', 'twitter_features.txt']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['twitter_data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        # In this case, you're not downloading any data,\n",
    "        # but you could add code to download your data here if it's not local\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        # Load the graph data\n",
    "        edges = pd.read_csv(self.raw_paths[0], delimiter=' ', header=None)\n",
    "        features = pd.read_csv(self.raw_paths[1], delimiter=' ', header=None)\n",
    "\n",
    "        # Create the graph\n",
    "        edge_index = torch.tensor(edges.values, dtype=torch.long).t().contiguous()\n",
    "        x = torch.tensor(features.values, dtype=torch.float)\n",
    "    \n",
    "        data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "        data, slices = self.collate([data])\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "        \n",
    "class GPlusDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(GPlusDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['gplus_combined.txt', 'gplus_features.txt']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['gplus_data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        # In this case, you're not downloading any data,\n",
    "        # but you could add code to download your data here if it's not local\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        # Load the graph data\n",
    "        edges = pd.read_csv(self.raw_paths[0], delimiter=' ', header=None)\n",
    "        features = pd.read_csv(self.raw_paths[1], delimiter=' ', header=None)\n",
    "\n",
    "        # Create the graph\n",
    "        edge_index = torch.tensor(edges.values, dtype=torch.long).t().contiguous()\n",
    "        x = torch.tensor(features.values, dtype=torch.float)\n",
    "    \n",
    "        data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "        data, slices = self.collate([data])\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85be3285-acd5-4474-a38c-0e59aaed5847",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacebookDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(FacebookDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['facebook_combined.txt', 'facebook_features.txt']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def download(self):\n",
    "        # In this case, you're not downloading any data,\n",
    "        # but you could add code to download your data here if it's not local\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        # Load the graph data\n",
    "        edges = pd.read_csv(self.raw_paths[0], delimiter=' ', header=None)\n",
    "        features = pd.read_csv(self.raw_paths[1], delimiter=' ', header=None)\n",
    "\n",
    "        # Create the graph\n",
    "        edge_index = torch.tensor(edges.values, dtype=torch.long).t().contiguous()\n",
    "        x = torch.tensor(features.values, dtype=torch.float)\n",
    "    \n",
    "        data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "        data, slices = self.collate([data])\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67b12142-a9ed-4579-9803-2e42be884e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FacebookDataset(root='.')\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd2f673c-3f99-4792-bcdd-8b034f8548f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Train Positives\n",
    "# Define the percentage of edges to remove\n",
    "test_percentage = 0.3\n",
    "\n",
    "# Calculate the number of edges to remove\n",
    "num_edges_to_remove = int(data.edge_index.shape[1] * test_percentage)\n",
    "\n",
    "# Shuffle the edges\n",
    "edge_indices = np.arange(data.edge_index.shape[1])\n",
    "np.random.shuffle(edge_indices)\n",
    "\n",
    "# Select the edges to keep\n",
    "edges_to_keep = edge_indices[num_edges_to_remove:]\n",
    "\n",
    "# Create a new graph with only the edges to keep(Train positives)\n",
    "data_prime = Data(x=data.x, edge_index=data.edge_index[:, edges_to_keep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d33966b-7563-47fe-99f1-a7ec50079019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train pos \n",
    "train_pos=data_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e7311e5-3c2a-4052-ae32-484a27280ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST POSITIVES\n",
    "# Select the edges to remove (these will be your test positives)\n",
    "edges_to_remove = edge_indices[:num_edges_to_remove]\n",
    "\n",
    "# Create a new graph with only the edges to remove (Test positives)\n",
    "test_pos = Data(x=data.x, edge_index=data.edge_index[:, edges_to_remove])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5e0b2fb-2730-4ead-b56a-e77c5b0fad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Train negatives\n",
    "positives_edges=data_prime.edge_index\n",
    "# Number of negative samples to generate\n",
    "num_neg_samples = data_prime.edge_index.size(1)\n",
    "# Generate negative samples\n",
    "negative_edge_index = negative_sampling(edge_index=data.edge_index, num_nodes=data.num_nodes, num_neg_samples=num_neg_samples)\n",
    "#Train negatives\n",
    "train_neg = Data(x=data.x, edge_index=negative_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c90983f-7f26-4171-8e7a-a0505ea191cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST negatives\n",
    "# Number of negative samples to generate for testing\n",
    "num_test_neg_samples = test_pos.edge_index.size(1)\n",
    "\n",
    "# Generate negative samples for testing\n",
    "test_negative_edge_index = negative_sampling(edge_index=data.edge_index, num_nodes=data.num_nodes, num_neg_samples=num_test_neg_samples)\n",
    "\n",
    "# Convert tensors to lists of tuples\n",
    "train_pos_edges = [tuple(edge) for edge in train_pos.edge_index.t().tolist()]\n",
    "test_pos_edges = [tuple(edge) for edge in test_pos.edge_index.t().tolist()]\n",
    "test_negative_edges = [tuple(edge) for edge in test_negative_edge_index.t().tolist()]\n",
    "\n",
    "# Ensure that these negative samples are not in the train_pos or test_pos sets\n",
    "test_neg_edge_index = [edge for edge in test_negative_edges if edge not in train_pos_edges and edge not in test_pos_edges]\n",
    "\n",
    "# Create the test_neg set\n",
    "test_neg = Data(x=data.x, edge_index=torch.tensor(test_neg_edge_index).t().contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9addb61-caf6-4572-98ad-9da3d37afbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_size):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_size)\n",
    "        self.conv2 = GCNConv(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, edge_index, x):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2426c759",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TruncatedSVDModel(torch.nn.Module):\n",
    "    def __init__(self, num_features, output_size):\n",
    "        super(TruncatedSVDModel, self).__init__()\n",
    "        self.svd = TruncatedSVD(n_components=output_size)\n",
    "        self.fc = torch.nn.Linear(output_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_svd = self.svd.fit_transform(x.numpy())\n",
    "        x_svd = torch.tensor(x_svd, dtype=torch.float)\n",
    "        x_out = self.fc(x_svd)\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d975d5df-22fc-43db-a010-09cde635aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotPredictor(torch.nn.Module):\n",
    "    def forward(self, edge_index, h):\n",
    "        # Get the embeddings of the source nodes and destination nodes\n",
    "        source_node_embeddings = h[edge_index[0]]\n",
    "        destination_node_embeddings = h[edge_index[1]]\n",
    "\n",
    "        # Compute the dot product (score) between source and destination node embeddings\n",
    "        scores = (source_node_embeddings * destination_node_embeddings).sum(dim=-1)\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c62a5c93-c91f-4c9d-8c59-2c227b36767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(model_name='GCN', hidden_size=64, epoch=100):\n",
    "    \n",
    "    def compute_loss(pos_score, neg_score):  # computes the loss based on binary cross entropy\n",
    "        scores = torch.cat([pos_score, neg_score])\n",
    "        labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
    "        return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "    def compute_auc(pos_score, neg_score):  # computes AUC (Area-Under-Curve) score\n",
    "        scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "        labels = torch.cat(\n",
    "            [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "        return roc_auc_score(labels, scores)\n",
    "       \n",
    "    # hidden_size is the size of the hidden layer in the neural net\n",
    "    if model_name == 'GCN':\n",
    "        model = GCN(data_prime.num_features, hidden_size)\n",
    "    elif model_name == 'TruncatedSVD':\n",
    "        model = TruncatedSVDModel(data_prime.num_features, hidden_size)\n",
    "        \n",
    "    pred = DotPredictor()\n",
    "    optimizer = torch.optim.SGD(itertools.chain(model.parameters(), pred.parameters()), lr=0.01, momentum=0.9)\n",
    "    # Use a learning rate scheduler\n",
    "    scheduler = StepLR(optimizer, step_size=500, gamma=0.5)\n",
    " \n",
    "\n",
    "        # ----------- training -------------------------------- #\n",
    "    train_g = data_prime\n",
    "    for e in range(epoch):\n",
    "        if model_name == 'GCN':\n",
    "            h = model(train_g.edge_index, train_g.x)\n",
    "        elif model_name == 'TruncatedSVD':\n",
    "            h = model(train_g.x)  # get node embeddings\n",
    "\n",
    "        # forward    \n",
    "        pos_score = pred(train_pos.edge_index, h)\n",
    "        neg_score = pred(train_neg.edge_index, h)\n",
    "        loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        if e % 10 == 0:\n",
    "            print('In epoch {}, loss: {}'.format(e, loss))\n",
    "\n",
    "    # ----------- test and check results ---------------- #\n",
    "    with torch.no_grad():\n",
    "        pos_score = pred(test_pos.edge_index, h)\n",
    "        neg_score = pred(test_neg.edge_index, h)\n",
    "        auc=compute_auc(pos_score, neg_score)\n",
    "        print('AUC', auc)  \n",
    "               \n",
    "    # Print model's state_dict\n",
    "    print(\"Model's state_dict:\")\n",
    "    for param_tensor in model.state_dict():\n",
    "        print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "    # Print optimizer's state_dict\n",
    "    print(\"Optimizer's state_dict:\")\n",
    "    for var_name in optimizer.state_dict():\n",
    "        print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "\n",
    "    # Print scheduler's state_dict\n",
    "    print(\"scheduler's state_dict:\")\n",
    "    for var_name in scheduler.state_dict():\n",
    "        print(var_name, \"\\t\", scheduler.state_dict()[var_name])\n",
    "    \n",
    "    torch.save({\n",
    "            'epoch': epoch,        \n",
    "            'epoch_rem': e,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'loss': loss,\n",
    "            \n",
    "            }, './torch_model/model_'+model_name+'_'+str(epoch)+'.pt')\n",
    "        \n",
    "    return h  # return node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "426437d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rec(h, user_id=0, k=10):\n",
    "    # `h` represents the node embeddings, with shape [num_nodes, hidden_size]\n",
    "\n",
    "    # generate a graph with (num_nodes - num_friends_of_user) edges\n",
    "    # one end of the edge is user_id\n",
    "    # the other end is a user that's NOT friends with user_id\n",
    "    user_friends = set()\n",
    "    user_neg_u, user_neg_v = [], []\n",
    "\n",
    "    for n1, n2 in data.edge_index.t().tolist():   # get all friends of user_id\n",
    "        if int(n1) == user_id:\n",
    "            user_friends.add(int(n2))\n",
    "        if int(n2) == user_id:\n",
    "            user_friends.add(int(n1))\n",
    "\n",
    "    num_nodes=data.x.shape[0]\n",
    "    for i in range(num_nodes):  # generate \"negative edges\" for user_id\n",
    "        if i != user_id and i not in user_friends:\n",
    "            user_neg_u.append(user_id)\n",
    "            user_neg_v.append(i)\n",
    "\n",
    "    user_g = Data(x=data.x,edge_index=torch.tensor([user_neg_u, user_neg_v] ))\n",
    "\n",
    "    pred = DotPredictor()\n",
    "\n",
    "    # calculate the score of each user\n",
    "    scores = []\n",
    "    for i, score in enumerate(pred(user_g.edge_index, h)):\n",
    "        rel=1 if ((user_id,i) in test_pos_edges) else 0\n",
    "        scores.append((i, score,rel))\n",
    "\n",
    "    # produce final ranked list\n",
    "    scores.sort(key=lambda x: -x[1])\n",
    "\n",
    "    # display results\n",
    "    \n",
    "    if (k !=0):\n",
    "        print(f\"List of 5 suggested friends for user {user_id}:\")\n",
    "    for i in range(k):\n",
    "        print(f'- User {scores[i][0]}, score = {scores[i][1]}, rel = {scores[i][2]}')\n",
    "    return scores[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd06a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rec(h, user_id=0, k=10):\n",
    "    user_friends = set()\n",
    "    user_neg_u, user_neg_v = [], []\n",
    "\n",
    "    for n1, n2 in data.edge_index.t().tolist():   # get all friends of user_id\n",
    "        if int(n1) == user_id:\n",
    "            user_friends.add(int(n2))\n",
    "        if int(n2) == user_id:\n",
    "            user_friends.add(int(n1))\n",
    "\n",
    "    num_nodes=data.x.shape[0]\n",
    "    for i in range(num_nodes):  # generate \"negative edges\" for user_id\n",
    "        if i != user_id and i not in user_friends:\n",
    "            user_neg_u.append(user_id)\n",
    "            user_neg_v.append(i)\n",
    "\n",
    "    user_g = Data(x=data.x,edge_index=torch.tensor([user_neg_u, user_neg_v] ))\n",
    "\n",
    "    pred = DotPredictor()\n",
    "\n",
    "    # calculate the score of each user\n",
    "    scores = []\n",
    "    for i, score in enumerate(pred(user_g.edge_index, h)):\n",
    "        rel=1 if ((user_id,i) in test_pos_edges) else 0\n",
    "        scores.append((i, score,rel))\n",
    "\n",
    "    # produce final ranked list\n",
    "    scores.sort(key=lambda x: -x[1])\n",
    "    rel=[x[2] for x in scores]\n",
    "    # display results\n",
    "    \n",
    "    return rel[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68a50391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(a,k=50):\n",
    "    top_k = a[:k]\n",
    "    hits=pd.DataFrame(0,index=[0],columns=top_k.columns)\n",
    "    recipr=pd.DataFrame(0,index=[0],columns=top_k.columns)\n",
    "    dcg=pd.DataFrame(0,index=[0],columns=top_k.columns)\n",
    "    idcg=pd.DataFrame(0,index=[0],columns=top_k.columns)\n",
    "    for i in list(top_k.columns):\n",
    "        hits[i]=(top_k[i].sum()/k)\n",
    "        recipr[i]=top_k.index[top_k[i] == 1].min()\n",
    "        dcg[i]=0\n",
    "        idcg[i]=0\n",
    "        top_sort=top_k[i]\n",
    "        top_sort=top_sort.sort_values(ascending=False)\n",
    "        for j in range(0,k):\n",
    "            dcg[i]+=top_k[i].iloc[j]/np.log2(j+1+1)\n",
    "            idcg[i]+=top_sort.iloc[j]/np.log2(j+1+1)\n",
    "\n",
    "    recipr=recipr.replace(np.nan,-1) +1\n",
    "    recipr = recipr.loc[:, (recipr != 0).any()]\n",
    "    ndcg=dcg/idcg\n",
    "    ndcg=ndcg.T.replace(np.nan,0)\n",
    "\n",
    "    ndcg_k=np.mean(ndcg)\n",
    "    mrr=(1/recipr.T).sum()[0]/len(a.columns)\n",
    "    hits_at_k=np.mean(hits)\n",
    "\n",
    "    print('Hits@'+str(k)+':', hits_at_k)\n",
    "    print('NDCG@'+str(k)+':', ndcg_k)\n",
    "    print('MRR:', mrr)\n",
    "    \n",
    "    return hits_at_k, ndcg_k, mrr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380dd537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f717a06-f73a-4f7f-84f5-a45294ef276f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vkaraiskos/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:251: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 0.6360924243927002\n",
      "In epoch 10, loss: 0.6108479499816895\n",
      "In epoch 20, loss: 0.576044499874115\n",
      "In epoch 30, loss: 0.5548127293586731\n",
      "In epoch 40, loss: 0.5355092883110046\n",
      "In epoch 50, loss: 0.522758960723877\n",
      "In epoch 60, loss: 0.5067281126976013\n",
      "In epoch 70, loss: 0.5022969245910645\n",
      "In epoch 80, loss: 0.49420297145843506\n",
      "In epoch 90, loss: 0.48290392756462097\n",
      "In epoch 100, loss: 0.48026585578918457\n",
      "In epoch 110, loss: 0.47341370582580566\n",
      "In epoch 120, loss: 0.46738937497138977\n",
      "In epoch 130, loss: 0.46773308515548706\n",
      "In epoch 140, loss: 0.4603409171104431\n",
      "In epoch 150, loss: 0.46276819705963135\n",
      "In epoch 160, loss: 0.4598846435546875\n",
      "In epoch 170, loss: 0.4583229124546051\n",
      "In epoch 180, loss: 0.4569869041442871\n",
      "In epoch 190, loss: 0.45694300532341003\n",
      "In epoch 200, loss: 0.4540381133556366\n",
      "In epoch 210, loss: 0.45437711477279663\n",
      "In epoch 220, loss: 0.45420098304748535\n",
      "In epoch 230, loss: 0.4507874846458435\n",
      "In epoch 240, loss: 0.4496913254261017\n",
      "In epoch 250, loss: 0.45276978611946106\n",
      "In epoch 260, loss: 0.4486519992351532\n",
      "In epoch 270, loss: 0.45008018612861633\n",
      "In epoch 280, loss: 0.4490017592906952\n",
      "In epoch 290, loss: 0.4503840208053589\n",
      "In epoch 300, loss: 0.4476315677165985\n",
      "In epoch 310, loss: 0.446328729391098\n",
      "In epoch 320, loss: 0.44659775495529175\n",
      "In epoch 330, loss: 0.44502270221710205\n",
      "In epoch 340, loss: 0.4439908564090729\n",
      "In epoch 350, loss: 0.44564834237098694\n",
      "In epoch 360, loss: 0.4455775022506714\n",
      "In epoch 370, loss: 0.44245603680610657\n",
      "In epoch 380, loss: 0.44347506761550903\n",
      "In epoch 390, loss: 0.4418259561061859\n",
      "In epoch 400, loss: 0.43704843521118164\n",
      "In epoch 410, loss: 0.44219478964805603\n",
      "In epoch 420, loss: 0.44107669591903687\n",
      "In epoch 430, loss: 0.44191622734069824\n",
      "In epoch 440, loss: 0.43868759274482727\n",
      "In epoch 450, loss: 0.43907803297042847\n",
      "In epoch 460, loss: 0.43968167901039124\n",
      "In epoch 470, loss: 0.43912482261657715\n",
      "In epoch 480, loss: 0.43924954533576965\n",
      "In epoch 490, loss: 0.43796294927597046\n",
      "In epoch 500, loss: 0.43729880452156067\n",
      "In epoch 510, loss: 0.4398824870586395\n",
      "In epoch 520, loss: 0.4384992718696594\n",
      "In epoch 530, loss: 0.43831679224967957\n",
      "In epoch 540, loss: 0.4360569715499878\n",
      "In epoch 550, loss: 0.436870276927948\n",
      "In epoch 560, loss: 0.43801450729370117\n",
      "In epoch 570, loss: 0.4366939067840576\n",
      "In epoch 580, loss: 0.43609344959259033\n",
      "In epoch 590, loss: 0.4374583959579468\n",
      "In epoch 600, loss: 0.43493297696113586\n",
      "In epoch 610, loss: 0.43750715255737305\n",
      "In epoch 620, loss: 0.4359457492828369\n",
      "In epoch 630, loss: 0.43553444743156433\n",
      "In epoch 640, loss: 0.4357945919036865\n",
      "In epoch 650, loss: 0.4367590844631195\n",
      "In epoch 660, loss: 0.4360879361629486\n",
      "In epoch 670, loss: 0.4346200227737427\n",
      "In epoch 680, loss: 0.4375689923763275\n",
      "In epoch 690, loss: 0.4357319176197052\n",
      "In epoch 700, loss: 0.43585848808288574\n",
      "In epoch 710, loss: 0.4345724582672119\n",
      "In epoch 720, loss: 0.4361346662044525\n",
      "In epoch 730, loss: 0.4362940490245819\n",
      "In epoch 740, loss: 0.43428224325180054\n",
      "In epoch 750, loss: 0.43437659740448\n",
      "In epoch 760, loss: 0.4340048134326935\n",
      "In epoch 770, loss: 0.43432268500328064\n",
      "In epoch 780, loss: 0.434693306684494\n",
      "In epoch 790, loss: 0.4355170428752899\n",
      "In epoch 800, loss: 0.4325657784938812\n",
      "In epoch 810, loss: 0.4339791536331177\n",
      "In epoch 820, loss: 0.4331645369529724\n",
      "In epoch 830, loss: 0.43476399779319763\n",
      "In epoch 840, loss: 0.4337604343891144\n",
      "In epoch 850, loss: 0.4336201548576355\n",
      "In epoch 860, loss: 0.435234010219574\n",
      "In epoch 870, loss: 0.4343697130680084\n",
      "In epoch 880, loss: 0.43420639634132385\n",
      "In epoch 890, loss: 0.43217384815216064\n",
      "In epoch 900, loss: 0.43313977122306824\n",
      "In epoch 910, loss: 0.4330757260322571\n",
      "In epoch 920, loss: 0.43302518129348755\n",
      "In epoch 930, loss: 0.43206116557121277\n",
      "In epoch 940, loss: 0.4336598217487335\n",
      "In epoch 950, loss: 0.43326666951179504\n",
      "In epoch 960, loss: 0.4329279661178589\n",
      "In epoch 970, loss: 0.4320524036884308\n",
      "In epoch 980, loss: 0.432578980922699\n",
      "In epoch 990, loss: 0.433597594499588\n",
      "AUC 0.9596090334140237\n",
      "Model's state_dict:\n",
      "conv1.bias \t torch.Size([64])\n",
      "conv1.lin.weight \t torch.Size([64, 1406])\n",
      "conv2.bias \t torch.Size([64])\n",
      "conv2.lin.weight \t torch.Size([64, 64])\n",
      "Optimizer's state_dict:\n",
      "state \t {0: {'momentum_buffer': tensor([-2.5604e-02, -1.7141e-02, -3.4154e-03, -3.8887e-02, -2.8916e-02,\n",
      "        -5.1800e-04,  3.8070e-05, -2.3084e-02, -1.6714e-05,  2.6997e-02,\n",
      "         7.4189e-03, -1.6215e-02,  5.7748e-04,  6.4172e-03, -1.7339e-02,\n",
      "         9.3928e-05, -2.0105e-04,  3.2779e-03,  1.3070e-02,  7.7605e-03,\n",
      "         1.8808e-02,  1.6998e-02, -2.5753e-03, -5.1737e-05, -7.0205e-03,\n",
      "         3.6172e-02,  1.3507e-02, -1.9486e-02, -4.9369e-03, -3.4793e-02,\n",
      "        -2.3454e-02, -2.7805e-02, -7.3373e-04,  8.7038e-03,  7.5582e-03,\n",
      "        -2.1749e-02, -6.0244e-03,  6.3494e-03,  2.3948e-03,  5.8929e-03,\n",
      "         2.0684e-02,  1.7061e-02,  9.7926e-03,  5.1466e-03,  3.0285e-02,\n",
      "        -1.3648e-02,  7.2223e-03,  2.6295e-02,  1.3805e-02,  1.5427e-03,\n",
      "         1.7732e-02,  1.8792e-02,  2.3501e-02,  1.4581e-02, -1.0079e-02,\n",
      "         1.5769e-02, -1.9586e-02,  3.0417e-02,  8.9250e-03, -4.4302e-03,\n",
      "         2.1498e-03,  6.3119e-03, -2.6346e-02, -5.5588e-03])}, 1: {'momentum_buffer': tensor([[-2.0127e-05, -1.8631e-04, -1.1024e-03,  ...,  8.3994e-07,\n",
      "         -4.4847e-06, -1.6283e-06],\n",
      "        [ 1.4475e-05,  1.5869e-05, -8.5036e-04,  ...,  1.4446e-04,\n",
      "          1.3869e-04,  4.5520e-05],\n",
      "        [ 2.5071e-06,  4.0099e-05, -2.3368e-04,  ..., -1.7386e-05,\n",
      "         -3.5814e-05, -1.5047e-05],\n",
      "        ...,\n",
      "        [-3.5460e-06, -1.1511e-04,  1.4608e-03,  ...,  2.1254e-05,\n",
      "          4.8463e-05, -2.7695e-05],\n",
      "        [ 2.4422e-05,  6.8022e-05, -6.8185e-04,  ...,  6.6126e-05,\n",
      "          9.1292e-05,  1.3908e-05],\n",
      "        [ 1.5848e-06,  1.1493e-04,  7.6743e-04,  ...,  5.4147e-06,\n",
      "          9.4095e-07, -3.7638e-05]])}, 2: {'momentum_buffer': tensor([-0.0049,  0.0021,  0.0079,  0.0038, -0.0035, -0.0124,  0.0027,  0.0092,\n",
      "         0.0024, -0.0083, -0.0088,  0.0049,  0.0108, -0.0035, -0.0100, -0.0240,\n",
      "         0.0045, -0.0114, -0.0036,  0.0123,  0.0074,  0.0110, -0.0021,  0.0142,\n",
      "        -0.0096, -0.0041,  0.0141, -0.0158, -0.0026,  0.0005, -0.0051, -0.0088,\n",
      "         0.0183, -0.0094,  0.0076, -0.0075,  0.0014,  0.0066,  0.0114,  0.0044,\n",
      "        -0.0044,  0.0050, -0.0018, -0.0064, -0.0055, -0.0126, -0.0115, -0.0044,\n",
      "         0.0129, -0.0017, -0.0009,  0.0077,  0.0198,  0.0194,  0.0074,  0.0046,\n",
      "        -0.0021, -0.0014, -0.0002, -0.0037,  0.0045,  0.0174, -0.0107,  0.0082])}, 3: {'momentum_buffer': tensor([[-0.0005, -0.0009,  0.0009,  ..., -0.0013, -0.0006, -0.0012],\n",
      "        [ 0.0002,  0.0004,  0.0001,  ...,  0.0002,  0.0004,  0.0003],\n",
      "        [ 0.0020,  0.0012,  0.0027,  ...,  0.0023,  0.0021,  0.0010],\n",
      "        ...,\n",
      "        [ 0.0030,  0.0022,  0.0038,  ...,  0.0035,  0.0036,  0.0023],\n",
      "        [-0.0011, -0.0004, -0.0034,  ..., -0.0020, -0.0032, -0.0020],\n",
      "        [ 0.0013,  0.0010,  0.0014,  ...,  0.0015,  0.0011,  0.0001]])}}\n",
      "param_groups \t [{'lr': 0.0025, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'initial_lr': 0.01, 'params': [0, 1, 2, 3]}]\n",
      "scheduler's state_dict:\n",
      "step_size \t 500\n",
      "gamma \t 0.5\n",
      "base_lrs \t [0.01]\n",
      "last_epoch \t 1000\n",
      "verbose \t False\n",
      "_step_count \t 1001\n",
      "_get_lr_called_within_step \t False\n",
      "_last_lr \t [0.0025]\n"
     ]
    }
   ],
   "source": [
    "h = pipeline(\"GCN\",epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6fba82b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3820/3820 [3:24:27<00:00,  3.21s/it]\n"
     ]
    }
   ],
   "source": [
    "target_users = np.unique(np.array(test_pos_edges).flatten())\n",
    "rankings={}\n",
    "with tqdm(total=len(target_users), position=0, leave=True) as pbar:\n",
    "    for user in target_users:         \n",
    "        rankings[user]=calc_rec(h,user)\n",
    "        pbar.update()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fbb511e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 0.8319059014320374\n",
      "In epoch 10, loss: 0.6391419768333435\n",
      "In epoch 20, loss: 0.6264968514442444\n",
      "In epoch 30, loss: 0.6207771897315979\n",
      "In epoch 40, loss: 0.6163594722747803\n",
      "In epoch 50, loss: 0.6100722551345825\n",
      "In epoch 60, loss: 0.6041662096977234\n",
      "In epoch 70, loss: 0.6012915372848511\n",
      "In epoch 80, loss: 0.5962530970573425\n",
      "In epoch 90, loss: 0.591964840888977\n",
      "In epoch 100, loss: 0.5883418321609497\n",
      "In epoch 110, loss: 0.5851919651031494\n",
      "In epoch 120, loss: 0.5824350118637085\n",
      "In epoch 130, loss: 0.5787000060081482\n",
      "In epoch 140, loss: 0.5758125185966492\n",
      "In epoch 150, loss: 0.5737694501876831\n",
      "In epoch 160, loss: 0.5708563327789307\n",
      "In epoch 170, loss: 0.567463219165802\n",
      "In epoch 180, loss: 0.5653952360153198\n",
      "In epoch 190, loss: 0.5638371109962463\n",
      "In epoch 200, loss: 0.5628612637519836\n",
      "In epoch 210, loss: 0.5612289309501648\n",
      "In epoch 220, loss: 0.5587643384933472\n",
      "In epoch 230, loss: 0.5574308037757874\n",
      "In epoch 240, loss: 0.555939257144928\n",
      "In epoch 250, loss: 0.5546720027923584\n",
      "In epoch 260, loss: 0.5527260303497314\n",
      "In epoch 270, loss: 0.5515633225440979\n",
      "In epoch 280, loss: 0.5507698655128479\n",
      "In epoch 290, loss: 0.551199197769165\n",
      "In epoch 300, loss: 0.548389732837677\n",
      "In epoch 310, loss: 0.5474949479103088\n",
      "In epoch 320, loss: 0.546774685382843\n",
      "In epoch 330, loss: 0.5462205410003662\n",
      "In epoch 340, loss: 0.5456066131591797\n",
      "In epoch 350, loss: 0.545310378074646\n",
      "In epoch 360, loss: 0.5441046357154846\n",
      "In epoch 370, loss: 0.5440740585327148\n",
      "In epoch 380, loss: 0.5430415868759155\n",
      "In epoch 390, loss: 0.5423741936683655\n",
      "In epoch 400, loss: 0.5422307848930359\n",
      "In epoch 410, loss: 0.5411298274993896\n",
      "In epoch 420, loss: 0.5414837002754211\n",
      "In epoch 430, loss: 0.5400946140289307\n",
      "In epoch 440, loss: 0.5393292307853699\n",
      "In epoch 450, loss: 0.5393404960632324\n",
      "In epoch 460, loss: 0.5389769673347473\n",
      "In epoch 470, loss: 0.5390099883079529\n",
      "In epoch 480, loss: 0.5386637449264526\n",
      "In epoch 490, loss: 0.5384660959243774\n",
      "In epoch 500, loss: 0.5375823378562927\n",
      "In epoch 510, loss: 0.5375518202781677\n",
      "In epoch 520, loss: 0.5377309918403625\n",
      "In epoch 530, loss: 0.5378003716468811\n",
      "In epoch 540, loss: 0.5367120504379272\n",
      "In epoch 550, loss: 0.5367518067359924\n",
      "In epoch 560, loss: 0.536698043346405\n",
      "In epoch 570, loss: 0.5369585752487183\n",
      "In epoch 580, loss: 0.5367937684059143\n",
      "In epoch 590, loss: 0.5373873114585876\n",
      "In epoch 600, loss: 0.5365981459617615\n",
      "In epoch 610, loss: 0.5355964303016663\n",
      "In epoch 620, loss: 0.5356521606445312\n",
      "In epoch 630, loss: 0.5358490347862244\n",
      "In epoch 640, loss: 0.5360814332962036\n",
      "In epoch 650, loss: 0.5355116724967957\n",
      "In epoch 660, loss: 0.535608172416687\n",
      "In epoch 670, loss: 0.5355168581008911\n",
      "In epoch 680, loss: 0.535391628742218\n",
      "In epoch 690, loss: 0.5347135663032532\n",
      "In epoch 700, loss: 0.5348489880561829\n",
      "In epoch 710, loss: 0.5352738499641418\n",
      "In epoch 720, loss: 0.5351066589355469\n",
      "In epoch 730, loss: 0.5352524518966675\n",
      "In epoch 740, loss: 0.5349365472793579\n",
      "In epoch 750, loss: 0.5340592265129089\n",
      "In epoch 760, loss: 0.5345349907875061\n",
      "In epoch 770, loss: 0.5346531867980957\n",
      "In epoch 780, loss: 0.5340099930763245\n",
      "In epoch 790, loss: 0.5337347388267517\n",
      "In epoch 800, loss: 0.5336742997169495\n",
      "In epoch 810, loss: 0.5338905453681946\n",
      "In epoch 820, loss: 0.5336896181106567\n",
      "In epoch 830, loss: 0.533598005771637\n",
      "In epoch 840, loss: 0.5337421894073486\n",
      "In epoch 850, loss: 0.5330259203910828\n",
      "In epoch 860, loss: 0.5340222716331482\n",
      "In epoch 870, loss: 0.533275842666626\n",
      "In epoch 880, loss: 0.5335943698883057\n",
      "In epoch 890, loss: 0.5330199599266052\n",
      "In epoch 900, loss: 0.5340966582298279\n",
      "In epoch 910, loss: 0.5323945879936218\n",
      "In epoch 920, loss: 0.5336019396781921\n",
      "In epoch 930, loss: 0.5320576429367065\n",
      "In epoch 940, loss: 0.5321937203407288\n",
      "In epoch 950, loss: 0.5322216749191284\n",
      "In epoch 960, loss: 0.5334749221801758\n",
      "In epoch 970, loss: 0.5326969623565674\n",
      "In epoch 980, loss: 0.5316622257232666\n",
      "In epoch 990, loss: 0.5332353711128235\n",
      "AUC 0.8556205398360319\n",
      "Model's state_dict:\n",
      "fc.weight \t torch.Size([64, 64])\n",
      "fc.bias \t torch.Size([64])\n",
      "Optimizer's state_dict:\n",
      "state \t {0: {'momentum_buffer': tensor([[-7.2722e-04, -3.4721e-03, -4.6762e-05,  ...,  2.9353e-05,\n",
      "          1.0329e-05,  9.3211e-05],\n",
      "        [ 2.9121e-04,  3.4986e-05,  6.2010e-04,  ..., -2.5758e-04,\n",
      "          3.6015e-04,  4.7318e-04],\n",
      "        [-4.1764e-04,  3.4088e-04,  2.9824e-03,  ..., -2.6665e-04,\n",
      "         -2.1399e-05, -7.5093e-04],\n",
      "        ...,\n",
      "        [-1.8882e-03,  7.2971e-04, -1.1359e-03,  ...,  2.1889e-04,\n",
      "          4.0645e-05, -3.3602e-04],\n",
      "        [ 6.8508e-05, -1.0986e-04, -1.8407e-03,  ...,  6.4304e-05,\n",
      "          9.5395e-05,  1.2002e-04],\n",
      "        [ 1.8400e-03,  1.9565e-03, -4.9660e-04,  ...,  2.3888e-04,\n",
      "          5.5827e-04, -1.0263e-03]])}, 1: {'momentum_buffer': tensor([-8.6100e-04, -1.6464e-03, -1.6543e-04, -6.9426e-04, -6.5733e-04,\n",
      "         4.8956e-04,  1.4884e-03, -1.2982e-03, -4.7996e-05,  3.3829e-05,\n",
      "        -1.4727e-03,  3.2891e-04, -1.8050e-03,  1.1369e-03,  2.7897e-03,\n",
      "        -9.0029e-04,  2.0075e-03,  3.7291e-03,  4.6387e-03,  1.3720e-03,\n",
      "        -1.1650e-03,  7.8496e-04,  4.4363e-04,  2.4540e-04, -1.2320e-03,\n",
      "         5.1637e-04, -1.7141e-03, -1.6010e-03, -4.2498e-04, -1.9216e-03,\n",
      "         3.1233e-03, -2.5286e-03, -1.4528e-04,  2.2816e-03, -5.9259e-04,\n",
      "        -2.9038e-03, -4.8812e-04, -9.5992e-04,  1.7155e-03, -1.2718e-03,\n",
      "         6.7414e-04, -1.2082e-03,  2.5060e-04, -2.5276e-04,  1.7478e-03,\n",
      "         1.0944e-03,  2.6477e-03, -1.7859e-03, -1.1234e-04, -5.7153e-04,\n",
      "        -9.6240e-04,  1.7347e-03,  2.9489e-04, -2.5279e-03, -1.0087e-03,\n",
      "         1.8250e-05,  1.9630e-03,  1.2523e-03, -6.1530e-04,  3.3199e-03,\n",
      "        -2.0303e-03,  4.1442e-04, -2.9907e-04, -1.1647e-04])}}\n",
      "param_groups \t [{'lr': 0.0025, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'initial_lr': 0.01, 'params': [0, 1]}]\n",
      "scheduler's state_dict:\n",
      "step_size \t 500\n",
      "gamma \t 0.5\n",
      "base_lrs \t [0.01]\n",
      "last_epoch \t 1000\n",
      "verbose \t False\n",
      "_step_count \t 1001\n",
      "_get_lr_called_within_step \t False\n",
      "_last_lr \t [0.0025]\n"
     ]
    }
   ],
   "source": [
    "h2 = pipeline(\"TruncatedSVD\",epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "778da106",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3820/3820 [3:25:34<00:00,  3.23s/it]\n"
     ]
    }
   ],
   "source": [
    "rankings2={}\n",
    "with tqdm(total=len(target_users), position=0, leave=True) as pbar:\n",
    "    for user in target_users:              \n",
    "        rankings2[user]=calc_rec(h2,user)\n",
    "        pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64e61450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@50: 0.009544502617801048\n",
      "NDCG@50: 0.08679938917996073\n",
      "MRR: 0.03602528725553057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.009544502617801048, 0.08679938917996073, 0.03602528725553057)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=pd.DataFrame(rankings)\n",
    "#all users\n",
    "metrics(a,k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2138068f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@5: 0.009633507853403141\n",
      "NDCG@5: 0.027250880903910743\n",
      "MRR: 0.021156195462478183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.009633507853403141, 0.027250880903910743, 0.021156195462478183)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(a,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e524b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to_csv('dot_product_gcn_all.csv', index=False) \n",
    "a.to_pickle('dot_product_gcn_all.pkl')\n",
    "torch.save(h, 'node_embeddings_gcn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c740d2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@50: 0.004816753926701571\n",
      "NDCG@50: 0.04478218425877151\n",
      "MRR: 0.017061470995251078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.004816753926701571, 0.04478218425877151, 0.017061470995251078)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2=pd.DataFrame(rankings2)\n",
    "#all users\n",
    "metrics(a2,k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "95b3fe9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@5: 0.004397905759162304\n",
      "NDCG@5: 0.012585534683067784\n",
      "MRR: 0.009694589877835953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.004397905759162304, 0.012585534683067784, 0.009694589877835953)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(a2,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22e79eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2.to_csv('dot_product_TruncatedSVD_all.csv', index=False) \n",
    "a2.to_pickle('dot_product_TruncatedSVD_all.pkl')\n",
    "torch.save(h2, 'node_embeddings_TruncatedSVD.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ecc60",
   "metadata": {},
   "source": [
    "|model|AUC|hits@5|NDCG@5| MRR  |hits@50|NDCG@50|MRR|\n",
    "|-----|---|---|------|------|-------|-------|---|\n",
    "| GCN |0.9596|0.0096|0.0273|0.0212| 0.0095|0.0868 |0.036  |\n",
    "|tSVD |0.8556|0.0043|0.0126|0.0097| 0.0048|0.0448 |0.017 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8a7197f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load if unloaded and get recommendations\n",
    "if 'h' not in globals() or 'h' not in locals():\n",
    "    h=torch.load('node_embeddings_gcn.pt')\n",
    "if 'a' not in globals() or 'a' not in locals():\n",
    "    a = pd.read_pickle('dot_product_gcn_all.pkl')\n",
    "if 'h2' not in globals() or 'h2' not in locals():\n",
    "    h=torch.load('node_embeddings_TruncatedSVD.pt')\n",
    "if 'a2' not in globals() or 'a2' not in locals():\n",
    "    a = pd.read_pickle('dot_product_TruncatedSVD_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c8cfc016",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 5 suggested friends for user 40:\n",
      "- User 232, score = 2.4407334327697754, rel = 1\n",
      "- User 107, score = 2.2264106273651123, rel = 0\n",
      "- User 225, score = 2.206943988800049, rel = 0\n",
      "- User 170, score = 2.0902135372161865, rel = 0\n",
      "- User 212, score = 2.015990972518921, rel = 1\n"
     ]
    }
   ],
   "source": [
    "sc=generate_rec(h, user_id=40, k=5) #k only for visualization here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6774d651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 5 suggested friends for user 40:\n",
      "- User 153, score = 3.9653868675231934, rel = 0\n",
      "- User 2238, score = 3.624063014984131, rel = 0\n",
      "- User 2090, score = 3.6001768112182617, rel = 0\n",
      "- User 1898, score = 3.505584239959717, rel = 0\n",
      "- User 210, score = 3.4285125732421875, rel = 0\n"
     ]
    }
   ],
   "source": [
    "sc2=generate_rec(h2, user_id=40, k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
